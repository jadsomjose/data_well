{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knn_teste.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDLChYU7vpanyQV3lqSdJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jadsomjose/data_well/blob/main/knn_teste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP3NTQm-jEON",
        "outputId": "71275d98-17d2-456f-ba60-4d859ec7b4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data_well'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 61 (delta 16), reused 55 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jadsomjose/data_well.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lasio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxyY2ZGZjY-X",
        "outputId": "f49d9be8-1fcb-4800-fc82-c302e9c9f1ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lasio\n",
            "  Downloading lasio-0.30-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lasio) (1.21.6)\n",
            "Installing collected packages: lasio\n",
            "Successfully installed lasio-0.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from math import pi as PI\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lasio\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "id": "x1tQnb94jgKo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norne1 = lasio.read('data_well/dado_norne/660810-B-4AH.las').df()\n",
        "norne2 = lasio.read('data_well/dado_norne/660810-C-1H.las').df()\n",
        "norne3 = lasio.read('data_well/dado_norne/660810-C-2H.las').df()\n",
        "norne4 = lasio.read('data_well/dado_norne/660810-C-3H.las').df()\n",
        "norne5 = lasio.read('data_well/dado_norne/660810-C-4AH.las').df()\n",
        "norne6 = lasio.read('data_well/dado_norne/660810-D-4H.las').df()\n",
        "norne7 = lasio.read('data_well/dado_norne/660810-E-3H.las').df()\n",
        "\n",
        "\n",
        "\n",
        "norne1 = norne1.dropna(subset=['DT', 'NPHI', 'VSH', 'DTS'])\n",
        "norne2 = norne2.dropna(subset=['DT', 'NPHI', 'VSH', 'DTS'])\n",
        "norne3 = norne3.dropna(subset=['DT', 'NPHI', 'VSH', 'DTS'])\n",
        "norne4 = norne4.dropna(subset=['DT', 'NPHI', 'VSH', 'DTS'])\n",
        "norne5 = norne5.dropna(subset=['DT', 'NPHI', 'VSH', 'DTS'])\n",
        "norne6 = norne6.dropna(subset=['DT', 'NPHI', 'VSH', 'DTS'])\n",
        "norne7 = norne7.dropna(subset=['DT', 'NPHI', 'VSH', 'DTS'])\n"
      ],
      "metadata": {
        "id": "MfdMzQgDjk28"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = norne1.loc[:, ['DT']]#, 'NPHI', 'VSH']]\n",
        "X2 = norne2.loc[:, ['DT']]#, 'NPHI', 'VSH']]\n",
        "X3 = norne3.loc[:, ['DT']]#, 'NPHI', 'VSH']]\n",
        "X4 = norne4.loc[:, ['DT']]#, 'NPHI', 'VSH']]\n",
        "X5 = norne5.loc[:, ['DT']]#, 'NPHI', 'VSH']]\n",
        "X6 = norne6.loc[:, ['DT']]#, 'NPHI', 'VSH']]\n",
        "X7 = norne7.loc[:, ['DT']]#, 'NPHI', 'VSH']]\n",
        "\n",
        "depth1 = norne1.index\n",
        "depth2 = norne2.index\n",
        "\n",
        "y1 = norne1.loc[:, ['DTS']]\n",
        "y2 = norne2.loc[:, ['DTS']]\n",
        "y3 = norne3.loc[:, ['DTS']]\n",
        "y4 = norne4.loc[:, ['DTS']]\n",
        "y5 = norne5.loc[:, ['DTS']]\n",
        "y6 = norne6.loc[:, ['DTS']]\n",
        "y7 = norne7.loc[:, ['DTS']]\n",
        "\n",
        "# Definir quem é poço cego e quem é poço de treinamento\n",
        "\n",
        "X_ref = X1 #pd.concat([X2, X3])#, X4, X5, X6, X7])\n",
        "y_ref = y1  #pd.concat([y2, y3])# y4, y5, y6, y7])\n",
        "\n",
        "X_blind = X2 #blind--> validaçÃO\n",
        "y_blind = y2"
      ],
      "metadata": {
        "id": "rhf0f7R1jpgP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculo das velocidades"
      ],
      "metadata": {
        "id": "-0vi4Lgtkcst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculando VP e VS\n",
        "\n",
        "$V_P=10^3 \\frac{0.3048}{\\Delta t_P}$ --> km/s\n"
      ],
      "metadata": {
        "id": "kBGyplftGZqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ref['VP'] = (0.3048/X_ref['DT'])*10**3\n",
        "X_blind['VP'] = (0.3048/X_blind['DT'])*10**3\n",
        "\n",
        "y_ref['VPS'] = (0.3048/y_ref['DTS'])*10**3\n",
        "y_blind['VPS'] = (0.3048/y_blind['DTS'])*10**3"
      ],
      "metadata": {
        "id": "iVP15gS9kg1u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(7,7))\n",
        "ax = plt.axes()\n",
        "ax.set_title('Vp- Norne 1') # Traning Data\n",
        "ax.set_xlabel(\"VP [km/s]\")\n",
        "ax.set_ylabel(\"Depth [m]\")\n",
        "\n",
        "ax.plot(X_ref['VP'],depth1)\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_ref['VP'],\n",
        "                                                    y_ref['VPS'],\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 1)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (7,7))\n",
        "ax = plt.axes()\n",
        "\n",
        "ax.scatter(x_train, y_train, label = \"Train set\")\n",
        "ax.scatter(x_test, y_test, label = \"Test set\")\n",
        "ax.legend()\n"
      ],
      "metadata": {
        "id": "D4ioJ78QlNpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "import lasio\n",
        "from sklearn.preprocessing import RobustScaler"
      ],
      "metadata": {
        "id": "SuufJP6e9Ev-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dado_wyoming1 = lasio.read('dado_Penobscot/Penobscot_B_41_LASOut_W4.las').df()[984:4200]\n",
        "dado_wyoming1['NPHISS'] = dado_wyoming1['NPHISS']*100\n",
        "\n",
        "dado_wyoming1 = dado_wyoming1.dropna(subset=['NPHISS', 'GRD','DT', 'RHOB'])    \n",
        "\n",
        "#X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])\n",
        "\n",
        "X = dado_wyoming1.loc[:, ['NPHISS', 'GRD','DT']]\n",
        "X_scaler = RobustScaler().fit_transform(X)\n",
        "y = dado_wyoming1.loc[:,['RHOB']]\n",
        "y = np.array(y)\n",
        "depth = np.array(dado_wyoming1.index)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3 )\n",
        "\n",
        "pcr = make_pipeline(StandardScaler(), PCA(n_components=2), LinearRegression())\n",
        "pcr.fit(X_train, y_train)\n",
        "pca = pcr.named_steps[\"pca\"]  # retrieve the PCA step of the pipeline\n",
        "\n",
        "pls = PLSRegression(n_components=1)\n",
        "pls.fit(X_train, y_train)\n",
        "\n",
        "y_pcr= pcr.predict(X_test)\n",
        "y_pls= pls.predict(X_test)\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "plt.plot(y_test, label = 'TEST')\n",
        "plt.plot(y_pls, label = 'PLS')\n",
        "plt.plot(y_pcr, label = 'PCR')\n",
        "\n",
        "\n",
        "plt.legend(loc='best')\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "msa_pcr= mean_absolute_error(y_test, y_pcr)\n",
        "r2_score_pcr = pcr.score(X_test,y_test)\n",
        "mse_pcr = mean_squared_error(y_test, y_pcr)\n",
        "\n",
        "print('PCR_METRICS: RMSE = {}, MSE = {}, MSA = {}, R2_score = {}'.format(mse_pcr**(1/2), mse_pcr, msa_pcr, r2_score_pcr))\n",
        "\n",
        "msa_pls= mean_absolute_error(y_test, y_pls)\n",
        "r2_score_pls = r2_score(y_test,y_pls)\n",
        "mse_pls = mean_squared_error(y_test, y_pls)\n",
        "\n",
        "print('PLS_METRICS: RMSE = {}, MSE = {}, MSA = {}, R2_score = {}'.format(mse_pls**(1/2), mse_pls, msa_pls, r2_score_pls))"
      ],
      "metadata": {
        "id": "RQR423yl9GFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}